import { normalizeCveId } from "./normalize";
import type { SearchMode } from "./types";

export type ParsedSearchKind = "cveId" | "product" | "text";

export interface ParsedCveSearchQuery {
  kind: ParsedSearchKind;
  tokens: string[];
  includeTerms: string[];
  excludeTerms: string[];
  raw: string;
}

const CVE_ID_PATTERN = /^CVE-\d{4}-\d{4,}$/i;
const PREFIX_PATTERN_SOURCE = "\\b(product|vendor|package|cpe|text):(?:\"([^\"]+)\"|'([^']+)'|(\\S+))";

const PRODUCT_COLLISION_RULES: Record<string, string[]> = {
  react: ["reactos", "reactor", "reactions"],
};

type QueryPrefix = "product" | "vendor" | "package" | "cpe" | "text";

interface ParsedPrefixes {
  product: string[];
  vendor: string[];
  package: string[];
  cpe: string[];
  text: string[];
}

function unique(values: string[]): string[] {
  return Array.from(new Set(values));
}

function normalizeTerm(value: string): string {
  return value.trim().toLowerCase();
}

function splitTerms(value: string): string[] {
  return value
    .split(/\s+/)
    .map((term) => normalizeTerm(term))
    .filter((term) => term.length > 0);
}

function extractLexicalTokens(value: string): string[] {
  return (value.toLowerCase().match(/[a-z0-9][a-z0-9._:+/-]*/g) ?? []).filter(
    (token) => token.length > 0,
  );
}

function emptyPrefixes(): ParsedPrefixes {
  return {
    product: [],
    vendor: [],
    package: [],
    cpe: [],
    text: [],
  };
}

function extractPrefixedTerms(raw: string): { prefixes: ParsedPrefixes; remainder: string } {
  const prefixes = emptyPrefixes();
  const prefixPattern = new RegExp(PREFIX_PATTERN_SOURCE, "gi");

  for (const match of raw.matchAll(prefixPattern)) {
    const prefix = (match[1] ?? "") as QueryPrefix;
    const value = match[2] ?? match[3] ?? match[4] ?? "";
    prefixes[prefix].push(...splitTerms(value));
  }

  const remainder = raw.replace(new RegExp(PREFIX_PATTERN_SOURCE, "gi"), " ").trim();
  return {
    prefixes,
    remainder,
  };
}

function resolveMode(mode: SearchMode | undefined): SearchMode {
  if (mode === "product" || mode === "text") {
    return mode;
  }

  return "auto";
}

function buildExcludeTerms(tokens: string[], explicitTokens: Set<string>): string[] {
  const excludes: string[] = [];

  for (const token of tokens) {
    const candidates = PRODUCT_COLLISION_RULES[token] ?? [];
    for (const candidate of candidates) {
      if (!explicitTokens.has(candidate)) {
        excludes.push(candidate);
      }
    }
  }

  return unique(excludes);
}

export function parseCveSearchQuery(rawQuery: string, mode?: SearchMode): ParsedCveSearchQuery {
  const raw = rawQuery.trim();

  if (raw.length === 0) {
    const resolvedMode = resolveMode(mode);
    return {
      kind: resolvedMode === "product" ? "product" : "text",
      tokens: [],
      includeTerms: [],
      excludeTerms: [],
      raw,
    };
  }

  if (CVE_ID_PATTERN.test(raw)) {
    const normalizedId = normalizeCveId(raw);
    return {
      kind: "cveId",
      tokens: [normalizedId.toLowerCase()],
      includeTerms: [normalizedId],
      excludeTerms: [],
      raw,
    };
  }

  const { prefixes, remainder } = extractPrefixedTerms(raw);
  const hasTextPrefix = prefixes.text.length > 0;
  const hasProductPrefix =
    prefixes.product.length > 0 ||
    prefixes.vendor.length > 0 ||
    prefixes.package.length > 0 ||
    prefixes.cpe.length > 0;

  let kind: ParsedSearchKind;
  let includeTerms: string[];

  if (hasTextPrefix || hasProductPrefix) {
    if (hasTextPrefix) {
      kind = "text";
      includeTerms = [
        ...prefixes.text,
        ...prefixes.product,
        ...prefixes.vendor,
        ...prefixes.package,
        ...prefixes.cpe,
        ...splitTerms(remainder),
      ];
    } else {
      kind = "product";
      includeTerms = [
        ...prefixes.product,
        ...prefixes.vendor,
        ...prefixes.package,
        ...prefixes.cpe,
        ...splitTerms(remainder),
      ];
    }
  } else {
    includeTerms = splitTerms(raw);

    const resolvedMode = resolveMode(mode);
    if (resolvedMode === "auto") {
      kind = includeTerms.length <= 1 ? "product" : "text";
    } else {
      kind = resolvedMode;
    }
  }

  includeTerms = unique(includeTerms);

  const tokens = unique(includeTerms.flatMap((term) => extractLexicalTokens(term)));
  const explicitTokens = new Set(extractLexicalTokens(raw));

  return {
    kind,
    tokens,
    includeTerms,
    excludeTerms: kind === "product" ? buildExcludeTerms(tokens, explicitTokens) : [],
    raw,
  };
}
